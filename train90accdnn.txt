(env) C:\Users\Veda\Documents\CSE847\project\dnn_examples>python train_90accdnn.py
Using TensorFlow backend.
C:\Users\Veda\Documents\CSE847\project\dnn_examples\env\lib\site-packages\tensorflow\python\framework\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it wi
ll be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
C:\Users\Veda\Documents\CSE847\project\dnn_examples\env\lib\site-packages\tensorflow\python\framework\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it wi
ll be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
C:\Users\Veda\Documents\CSE847\project\dnn_examples\env\lib\site-packages\tensorflow\python\framework\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it wi
ll be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
C:\Users\Veda\Documents\CSE847\project\dnn_examples\env\lib\site-packages\tensorflow\python\framework\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it wi
ll be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
C:\Users\Veda\Documents\CSE847\project\dnn_examples\env\lib\site-packages\tensorflow\python\framework\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it wi
ll be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
C:\Users\Veda\Documents\CSE847\project\dnn_examples\env\lib\site-packages\tensorflow\python\framework\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it wi
ll be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2021-07-30 19:43:26.789040: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2021-07-30 19:43:26.870636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties:
name: NVIDIA GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.759
pciBusID: 0000:01:00.0
totalMemory: 8.00GiB freeMemory: 7.04GiB
2021-07-30 19:43:26.870823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2021-07-30 19:43:27.453627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-30 19:43:27.453758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0
2021-07-30 19:43:27.453942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N
2021-07-30 19:43:27.454313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6793 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1
080, pci bus id: 0000:01:00.0, compute capability: 6.1)
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 32, 32, 32)        896
_________________________________________________________________
activation_1 (Activation)    (None, 32, 32, 32)        0
_________________________________________________________________
batch_normalization_1 (Batch (None, 32, 32, 32)        128
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248
_________________________________________________________________
activation_2 (Activation)    (None, 32, 32, 32)        0
_________________________________________________________________
batch_normalization_2 (Batch (None, 32, 32, 32)        128
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0
_________________________________________________________________
dropout_1 (Dropout)          (None, 16, 16, 32)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496
_________________________________________________________________
activation_3 (Activation)    (None, 16, 16, 64)        0
_________________________________________________________________
batch_normalization_3 (Batch (None, 16, 16, 64)        256
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928
_________________________________________________________________
activation_4 (Activation)    (None, 16, 16, 64)        0
_________________________________________________________________
batch_normalization_4 (Batch (None, 16, 16, 64)        256
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0
_________________________________________________________________
dropout_2 (Dropout)          (None, 8, 8, 64)          0
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856
_________________________________________________________________
activation_5 (Activation)    (None, 8, 8, 128)         0
_________________________________________________________________
batch_normalization_5 (Batch (None, 8, 8, 128)         512
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584
_________________________________________________________________
activation_6 (Activation)    (None, 8, 8, 128)         0
_________________________________________________________________
batch_normalization_6 (Batch (None, 8, 8, 128)         512
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0
_________________________________________________________________
dropout_3 (Dropout)          (None, 4, 4, 128)         0
_________________________________________________________________
flatten_1 (Flatten)          (None, 2048)              0
_________________________________________________________________
dense_1 (Dense)              (None, 10)                20490
=================================================================
Total params: 309,290
Trainable params: 308,394
Non-trainable params: 896
_________________________________________________________________
Epoch 1/125
781/781 [==============================] - 23s 30ms/step - loss: 1.8821 - acc: 0.4367 - val_loss: 1.3575 - val_acc: 0.5700
Epoch 2/125
781/781 [==============================] - 19s 24ms/step - loss: 1.2991 - acc: 0.5915 - val_loss: 1.3371 - val_acc: 0.6225
Epoch 3/125
781/781 [==============================] - 19s 24ms/step - loss: 1.0937 - acc: 0.6554 - val_loss: 0.9447 - val_acc: 0.7151
Epoch 4/125
781/781 [==============================] - 18s 23ms/step - loss: 0.9944 - acc: 0.6893 - val_loss: 0.9259 - val_acc: 0.7205
Epoch 5/125
781/781 [==============================] - 18s 23ms/step - loss: 0.9226 - acc: 0.7143 - val_loss: 0.8470 - val_acc: 0.7510
Epoch 6/125
781/781 [==============================] - 18s 23ms/step - loss: 0.8746 - acc: 0.7322 - val_loss: 0.8046 - val_acc: 0.7677
Epoch 7/125
781/781 [==============================] - 19s 25ms/step - loss: 0.8412 - acc: 0.7456 - val_loss: 0.9164 - val_acc: 0.7467
Epoch 8/125
781/781 [==============================] - 19s 25ms/step - loss: 0.8159 - acc: 0.7570 - val_loss: 0.7836 - val_acc: 0.7815
Epoch 9/125
781/781 [==============================] - 20s 26ms/step - loss: 0.7942 - acc: 0.7676 - val_loss: 0.7809 - val_acc: 0.7797
Epoch 10/125
781/781 [==============================] - 20s 26ms/step - loss: 0.7752 - acc: 0.7697 - val_loss: 0.7816 - val_acc: 0.7869
Epoch 11/125
781/781 [==============================] - 20s 25ms/step - loss: 0.7522 - acc: 0.7840 - val_loss: 0.7636 - val_acc: 0.7836
Epoch 12/125
781/781 [==============================] - 18s 23ms/step - loss: 0.7472 - acc: 0.7854 - val_loss: 0.6864 - val_acc: 0.8096
Epoch 13/125
781/781 [==============================] - 20s 25ms/step - loss: 0.7291 - acc: 0.7922 - val_loss: 0.7522 - val_acc: 0.7955
Epoch 14/125
781/781 [==============================] - 20s 26ms/step - loss: 0.7167 - acc: 0.7975 - val_loss: 0.7416 - val_acc: 0.8042
Epoch 15/125
781/781 [==============================] - 19s 24ms/step - loss: 0.7092 - acc: 0.8001 - val_loss: 0.6889 - val_acc: 0.8133
Epoch 16/125
781/781 [==============================] - 22s 28ms/step - loss: 0.7018 - acc: 0.8044 - val_loss: 0.6200 - val_acc: 0.8369
Epoch 17/125
781/781 [==============================] - 20s 26ms/step - loss: 0.6896 - acc: 0.8086 - val_loss: 0.6798 - val_acc: 0.8212
Epoch 18/125
781/781 [==============================] - 20s 25ms/step - loss: 0.6865 - acc: 0.8097 - val_loss: 0.6857 - val_acc: 0.8183
Epoch 19/125
781/781 [==============================] - 21s 27ms/step - loss: 0.6757 - acc: 0.8133 - val_loss: 0.6586 - val_acc: 0.8281
Epoch 20/125
781/781 [==============================] - 19s 24ms/step - loss: 0.6740 - acc: 0.8157 - val_loss: 0.6535 - val_acc: 0.8253
Epoch 21/125
781/781 [==============================] - 20s 25ms/step - loss: 0.6653 - acc: 0.8181 - val_loss: 0.6062 - val_acc: 0.8425
Epoch 22/125
781/781 [==============================] - 20s 25ms/step - loss: 0.6620 - acc: 0.8191 - val_loss: 0.7696 - val_acc: 0.7913
Epoch 23/125
781/781 [==============================] - 19s 25ms/step - loss: 0.6589 - acc: 0.8207 - val_loss: 0.6040 - val_acc: 0.8444
Epoch 24/125
781/781 [==============================] - 19s 24ms/step - loss: 0.6511 - acc: 0.8249 - val_loss: 0.6091 - val_acc: 0.8456
Epoch 25/125
781/781 [==============================] - 19s 24ms/step - loss: 0.6518 - acc: 0.8246 - val_loss: 0.6340 - val_acc: 0.8360
Epoch 26/125
781/781 [==============================] - 22s 28ms/step - loss: 0.6469 - acc: 0.8271 - val_loss: 0.6380 - val_acc: 0.8394
Epoch 27/125
781/781 [==============================] - 21s 27ms/step - loss: 0.6412 - acc: 0.8282 - val_loss: 0.6274 - val_acc: 0.8347
Epoch 28/125
781/781 [==============================] - 23s 30ms/step - loss: 0.6466 - acc: 0.8271 - val_loss: 0.5796 - val_acc: 0.8542
Epoch 29/125
781/781 [==============================] - 20s 26ms/step - loss: 0.6400 - acc: 0.8271 - val_loss: 0.6644 - val_acc: 0.8259
Epoch 30/125
781/781 [==============================] - 19s 25ms/step - loss: 0.6304 - acc: 0.8342 - val_loss: 0.5863 - val_acc: 0.8536
Epoch 31/125
781/781 [==============================] - 19s 24ms/step - loss: 0.6396 - acc: 0.8295 - val_loss: 0.5994 - val_acc: 0.8444
Epoch 32/125
781/781 [==============================] - 20s 26ms/step - loss: 0.6311 - acc: 0.8341 - val_loss: 0.6423 - val_acc: 0.8395
Epoch 33/125
781/781 [==============================] - 20s 26ms/step - loss: 0.6317 - acc: 0.8333 - val_loss: 0.6117 - val_acc: 0.8486
Epoch 34/125
781/781 [==============================] - 20s 25ms/step - loss: 0.6289 - acc: 0.8356 - val_loss: 0.5917 - val_acc: 0.8536
Epoch 35/125
781/781 [==============================] - 19s 25ms/step - loss: 0.6229 - acc: 0.8361 - val_loss: 0.6554 - val_acc: 0.8336
Epoch 36/125
781/781 [==============================] - 20s 25ms/step - loss: 0.6205 - acc: 0.8365 - val_loss: 0.5500 - val_acc: 0.8637
Epoch 37/125
781/781 [==============================] - 20s 25ms/step - loss: 0.6176 - acc: 0.8372 - val_loss: 0.6957 - val_acc: 0.8216
Epoch 38/125
781/781 [==============================] - 21s 26ms/step - loss: 0.6249 - acc: 0.8375 - val_loss: 0.5912 - val_acc: 0.8540
Epoch 39/125
781/781 [==============================] - 20s 25ms/step - loss: 0.6157 - acc: 0.8382 - val_loss: 0.5849 - val_acc: 0.8549
Epoch 40/125
781/781 [==============================] - 20s 25ms/step - loss: 0.6113 - acc: 0.8402 - val_loss: 0.6824 - val_acc: 0.8233
Epoch 41/125
781/781 [==============================] - 19s 25ms/step - loss: 0.6102 - acc: 0.8415 - val_loss: 0.5932 - val_acc: 0.8535
Epoch 42/125
781/781 [==============================] - 19s 24ms/step - loss: 0.6123 - acc: 0.8391 - val_loss: 0.6293 - val_acc: 0.8369
Epoch 43/125
781/781 [==============================] - 19s 24ms/step - loss: 0.6119 - acc: 0.8405 - val_loss: 0.6246 - val_acc: 0.8435
Epoch 44/125
781/781 [==============================] - 19s 25ms/step - loss: 0.6085 - acc: 0.8418 - val_loss: 0.6641 - val_acc: 0.8323
Epoch 45/125
781/781 [==============================] - 19s 24ms/step - loss: 0.6102 - acc: 0.8413 - val_loss: 0.5645 - val_acc: 0.8603
Epoch 46/125
781/781 [==============================] - 19s 24ms/step - loss: 0.6089 - acc: 0.8417 - val_loss: 0.6099 - val_acc: 0.8509
Epoch 47/125
781/781 [==============================] - 19s 24ms/step - loss: 0.6056 - acc: 0.8424 - val_loss: 0.6029 - val_acc: 0.8553
Epoch 48/125
781/781 [==============================] - 18s 24ms/step - loss: 0.6055 - acc: 0.8428 - val_loss: 0.5848 - val_acc: 0.8561
Epoch 49/125
781/781 [==============================] - 18s 23ms/step - loss: 0.6002 - acc: 0.8451 - val_loss: 0.6190 - val_acc: 0.8528
Epoch 50/125
781/781 [==============================] - 18s 24ms/step - loss: 0.6011 - acc: 0.8449 - val_loss: 0.6236 - val_acc: 0.8498
Epoch 51/125
781/781 [==============================] - 18s 23ms/step - loss: 0.6021 - acc: 0.8445 - val_loss: 0.5763 - val_acc: 0.8607
Epoch 52/125
781/781 [==============================] - 18s 23ms/step - loss: 0.5966 - acc: 0.8475 - val_loss: 0.5376 - val_acc: 0.8692
Epoch 53/125
781/781 [==============================] - 18s 24ms/step - loss: 0.5922 - acc: 0.8473 - val_loss: 0.6017 - val_acc: 0.8581
Epoch 54/125
781/781 [==============================] - 19s 24ms/step - loss: 0.5989 - acc: 0.8463 - val_loss: 0.6331 - val_acc: 0.8435
Epoch 55/125
781/781 [==============================] - 19s 25ms/step - loss: 0.5972 - acc: 0.8467 - val_loss: 0.6504 - val_acc: 0.8399
Epoch 56/125
781/781 [==============================] - 41s 53ms/step - loss: 0.5950 - acc: 0.8477 - val_loss: 0.5785 - val_acc: 0.8572
Epoch 57/125
781/781 [==============================] - 43s 55ms/step - loss: 0.5932 - acc: 0.8481 - val_loss: 0.5925 - val_acc: 0.8546
Epoch 58/125
781/781 [==============================] - 46s 59ms/step - loss: 0.5907 - acc: 0.8491 - val_loss: 0.7048 - val_acc: 0.8179
Epoch 59/125
781/781 [==============================] - 46s 59ms/step - loss: 0.5896 - acc: 0.8480 - val_loss: 0.5995 - val_acc: 0.8544
Epoch 60/125
781/781 [==============================] - 41s 52ms/step - loss: 0.5882 - acc: 0.8507 - val_loss: 0.5787 - val_acc: 0.8580
Epoch 61/125
781/781 [==============================] - 42s 54ms/step - loss: 0.5887 - acc: 0.8485 - val_loss: 0.5689 - val_acc: 0.8658
Epoch 62/125
781/781 [==============================] - 42s 54ms/step - loss: 0.5903 - acc: 0.8487 - val_loss: 0.6516 - val_acc: 0.8371
Epoch 63/125
781/781 [==============================] - 43s 55ms/step - loss: 0.5879 - acc: 0.8504 - val_loss: 0.5816 - val_acc: 0.8589
Epoch 64/125
781/781 [==============================] - 42s 54ms/step - loss: 0.5865 - acc: 0.8527 - val_loss: 0.6375 - val_acc: 0.8433
Epoch 65/125
781/781 [==============================] - 41s 53ms/step - loss: 0.5857 - acc: 0.8499 - val_loss: 0.5955 - val_acc: 0.8562
Epoch 66/125
781/781 [==============================] - 40s 51ms/step - loss: 0.5874 - acc: 0.8489 - val_loss: 0.6041 - val_acc: 0.8530
Epoch 67/125
781/781 [==============================] - 38s 49ms/step - loss: 0.5883 - acc: 0.8503 - val_loss: 0.6551 - val_acc: 0.8357
Epoch 68/125
781/781 [==============================] - 38s 49ms/step - loss: 0.5836 - acc: 0.8524 - val_loss: 0.6415 - val_acc: 0.8430
Epoch 69/125
781/781 [==============================] - 38s 49ms/step - loss: 0.5897 - acc: 0.8494 - val_loss: 0.6021 - val_acc: 0.8541
Epoch 70/125
781/781 [==============================] - 37s 47ms/step - loss: 0.5838 - acc: 0.8505 - val_loss: 0.6073 - val_acc: 0.8553
Epoch 71/125
781/781 [==============================] - 37s 48ms/step - loss: 0.5781 - acc: 0.8533 - val_loss: 0.6059 - val_acc: 0.8465
Epoch 72/125
781/781 [==============================] - 37s 47ms/step - loss: 0.5823 - acc: 0.8529 - val_loss: 0.5927 - val_acc: 0.8556
Epoch 73/125
781/781 [==============================] - 37s 47ms/step - loss: 0.5787 - acc: 0.8513 - val_loss: 0.5883 - val_acc: 0.8542
Epoch 74/125
781/781 [==============================] - 37s 48ms/step - loss: 0.5825 - acc: 0.8526 - val_loss: 0.5715 - val_acc: 0.8570
Epoch 75/125
781/781 [==============================] - 38s 49ms/step - loss: 0.5811 - acc: 0.8515 - val_loss: 0.5998 - val_acc: 0.8516
Epoch 76/125
781/781 [==============================] - 38s 49ms/step - loss: 0.5759 - acc: 0.8548 - val_loss: 0.5571 - val_acc: 0.8641
Epoch 77/125
781/781 [==============================] - 40s 51ms/step - loss: 0.5342 - acc: 0.8677 - val_loss: 0.5393 - val_acc: 0.8734
Epoch 78/125
781/781 [==============================] - 40s 51ms/step - loss: 0.5211 - acc: 0.8695 - val_loss: 0.5534 - val_acc: 0.8638
Epoch 79/125
781/781 [==============================] - 36s 46ms/step - loss: 0.5095 - acc: 0.8742 - val_loss: 0.5173 - val_acc: 0.8757
Epoch 80/125
781/781 [==============================] - 37s 47ms/step - loss: 0.5062 - acc: 0.8750 - val_loss: 0.5330 - val_acc: 0.8742
Epoch 81/125
781/781 [==============================] - 36s 46ms/step - loss: 0.4961 - acc: 0.8766 - val_loss: 0.5163 - val_acc: 0.8751
Epoch 82/125
781/781 [==============================] - 37s 48ms/step - loss: 0.4981 - acc: 0.8761 - val_loss: 0.5306 - val_acc: 0.8742
Epoch 83/125
781/781 [==============================] - 37s 48ms/step - loss: 0.4939 - acc: 0.8752 - val_loss: 0.5060 - val_acc: 0.8793
Epoch 84/125
781/781 [==============================] - 37s 47ms/step - loss: 0.4842 - acc: 0.8779 - val_loss: 0.5168 - val_acc: 0.8800
Epoch 85/125
781/781 [==============================] - 35s 45ms/step - loss: 0.4860 - acc: 0.8780 - val_loss: 0.5304 - val_acc: 0.8732
Epoch 86/125
781/781 [==============================] - 34s 43ms/step - loss: 0.4813 - acc: 0.8789 - val_loss: 0.5294 - val_acc: 0.8672
Epoch 87/125
781/781 [==============================] - 34s 44ms/step - loss: 0.4809 - acc: 0.8781 - val_loss: 0.5415 - val_acc: 0.8654
Epoch 88/125
781/781 [==============================] - 34s 44ms/step - loss: 0.4801 - acc: 0.8772 - val_loss: 0.5095 - val_acc: 0.8767
Epoch 89/125
781/781 [==============================] - 36s 46ms/step - loss: 0.4770 - acc: 0.8786 - val_loss: 0.5228 - val_acc: 0.8730
Epoch 90/125
781/781 [==============================] - 37s 48ms/step - loss: 0.4744 - acc: 0.8795 - val_loss: 0.4966 - val_acc: 0.8820
Epoch 91/125
781/781 [==============================] - 37s 48ms/step - loss: 0.4756 - acc: 0.8768 - val_loss: 0.4736 - val_acc: 0.8839
Epoch 92/125
781/781 [==============================] - 37s 48ms/step - loss: 0.4711 - acc: 0.8805 - val_loss: 0.5335 - val_acc: 0.8649
Epoch 93/125
781/781 [==============================] - 37s 47ms/step - loss: 0.4695 - acc: 0.8805 - val_loss: 0.4931 - val_acc: 0.8772
Epoch 94/125
781/781 [==============================] - 36s 46ms/step - loss: 0.4659 - acc: 0.8805 - val_loss: 0.5076 - val_acc: 0.8748
Epoch 95/125
781/781 [==============================] - 36s 46ms/step - loss: 0.4639 - acc: 0.8807 - val_loss: 0.4902 - val_acc: 0.8787
Epoch 96/125
781/781 [==============================] - 34s 44ms/step - loss: 0.4680 - acc: 0.8803 - val_loss: 0.4966 - val_acc: 0.8790
Epoch 97/125
781/781 [==============================] - 39s 50ms/step - loss: 0.4644 - acc: 0.8792 - val_loss: 0.5137 - val_acc: 0.8720
Epoch 98/125
781/781 [==============================] - 40s 51ms/step - loss: 0.4687 - acc: 0.8796 - val_loss: 0.4689 - val_acc: 0.8864
Epoch 99/125
781/781 [==============================] - 41s 53ms/step - loss: 0.4606 - acc: 0.8807 - val_loss: 0.4776 - val_acc: 0.8823
Epoch 100/125
781/781 [==============================] - 42s 54ms/step - loss: 0.4628 - acc: 0.8806 - val_loss: 0.4971 - val_acc: 0.8721
Epoch 101/125
781/781 [==============================] - 42s 54ms/step - loss: 0.4631 - acc: 0.8806 - val_loss: 0.5255 - val_acc: 0.8687
Epoch 102/125
781/781 [==============================] - 42s 54ms/step - loss: 0.4421 - acc: 0.8876 - val_loss: 0.4572 - val_acc: 0.8897
Epoch 103/125
781/781 [==============================] - 41s 52ms/step - loss: 0.4301 - acc: 0.8911 - val_loss: 0.4925 - val_acc: 0.8761
Epoch 104/125
781/781 [==============================] - 41s 52ms/step - loss: 0.4219 - acc: 0.8934 - val_loss: 0.4723 - val_acc: 0.8818
Epoch 105/125
781/781 [==============================] - 43s 55ms/step - loss: 0.4249 - acc: 0.8930 - val_loss: 0.4690 - val_acc: 0.8854
Epoch 106/125
781/781 [==============================] - 42s 54ms/step - loss: 0.4258 - acc: 0.8919 - val_loss: 0.4691 - val_acc: 0.8836
Epoch 107/125
781/781 [==============================] - 40s 51ms/step - loss: 0.4207 - acc: 0.8924 - val_loss: 0.4599 - val_acc: 0.8862
Epoch 108/125
781/781 [==============================] - 37s 47ms/step - loss: 0.4187 - acc: 0.8937 - val_loss: 0.4474 - val_acc: 0.8894
Epoch 109/125
781/781 [==============================] - 37s 47ms/step - loss: 0.4164 - acc: 0.8928 - val_loss: 0.4730 - val_acc: 0.8856
Epoch 110/125
781/781 [==============================] - 40s 51ms/step - loss: 0.4147 - acc: 0.8945 - val_loss: 0.4719 - val_acc: 0.8835
Epoch 111/125
781/781 [==============================] - 44s 57ms/step - loss: 0.4162 - acc: 0.8927 - val_loss: 0.5041 - val_acc: 0.8771
Epoch 112/125
781/781 [==============================] - 43s 56ms/step - loss: 0.4129 - acc: 0.8942 - val_loss: 0.4492 - val_acc: 0.8886
Epoch 113/125
781/781 [==============================] - 43s 55ms/step - loss: 0.4096 - acc: 0.8947 - val_loss: 0.4472 - val_acc: 0.8930
Epoch 114/125
781/781 [==============================] - 43s 55ms/step - loss: 0.4090 - acc: 0.8946 - val_loss: 0.4455 - val_acc: 0.8902
Epoch 115/125
781/781 [==============================] - 42s 53ms/step - loss: 0.4053 - acc: 0.8959 - val_loss: 0.4310 - val_acc: 0.8943
Epoch 116/125
781/781 [==============================] - 40s 51ms/step - loss: 0.4106 - acc: 0.8922 - val_loss: 0.4416 - val_acc: 0.8897
Epoch 117/125
781/781 [==============================] - 36s 47ms/step - loss: 0.4052 - acc: 0.8955 - val_loss: 0.4621 - val_acc: 0.8871
Epoch 118/125
781/781 [==============================] - 37s 47ms/step - loss: 0.4043 - acc: 0.8945 - val_loss: 0.4508 - val_acc: 0.8892
Epoch 119/125
781/781 [==============================] - 37s 47ms/step - loss: 0.4077 - acc: 0.8933 - val_loss: 0.4983 - val_acc: 0.8761
Epoch 120/125
781/781 [==============================] - 36s 46ms/step - loss: 0.4030 - acc: 0.8948 - val_loss: 0.4601 - val_acc: 0.8859
Epoch 121/125
781/781 [==============================] - 36s 46ms/step - loss: 0.4037 - acc: 0.8958 - val_loss: 0.4423 - val_acc: 0.8897
Epoch 122/125
781/781 [==============================] - 35s 45ms/step - loss: 0.4002 - acc: 0.8949 - val_loss: 0.4650 - val_acc: 0.8849
Epoch 123/125
781/781 [==============================] - 36s 46ms/step - loss: 0.4025 - acc: 0.8953 - val_loss: 0.4556 - val_acc: 0.8848
Epoch 124/125
781/781 [==============================] - 35s 45ms/step - loss: 0.3965 - acc: 0.8962 - val_loss: 0.4433 - val_acc: 0.8936
Epoch 125/125
781/781 [==============================] - 35s 45ms/step - loss: 0.3980 - acc: 0.8957 - val_loss: 0.4262 - val_acc: 0.8907
10000/10000 [==============================] - 2s 185us/step

Test result: 89.070 loss: 0.426
